/home/ids/hrami
0,1
no change     /home/ids/hrami/anaconda3/condabin/conda
no change     /home/ids/hrami/anaconda3/bin/conda
no change     /home/ids/hrami/anaconda3/bin/conda-env
no change     /home/ids/hrami/anaconda3/bin/activate
no change     /home/ids/hrami/anaconda3/bin/deactivate
no change     /home/ids/hrami/anaconda3/etc/profile.d/conda.sh
no change     /home/ids/hrami/anaconda3/etc/fish/conf.d/conda.fish
no change     /home/ids/hrami/anaconda3/shell/condabin/Conda.psm1
no change     /home/ids/hrami/anaconda3/shell/condabin/conda-hook.ps1
no change     /home/ids/hrami/anaconda3/lib/python3.9/site-packages/xontrib/conda.xsh
no change     /home/ids/hrami/anaconda3/etc/profile.d/conda.csh
no change     /home/ids/hrami/.bashrc
No action taken.
Virtual environment activated
training on TElecom Cluster
training on TElecom Cluster
gpu 0
gpu 1
0
1
==========
Args:Namespace(config='./S2P/OpenUnReID/tools/MMT/config.yaml', work_dir='./SpCL_test_2/', resume_from=None, launcher='pytorch', tcp_port='23204', exec=2.0, epochs=10, iters=120, KDloss=0.1, KD='S2P', MMDloss=0.1, set_cfgs=None)
==========
cfg.LOCAL_RANK: 0
cfg.DATA_ROOT: ../data/OpenUnReID/datasets
cfg.DATA_ROOT_local: /data/cvlab/home/ramih/Knowledge_Distilation/data/OpenUnReID/datasets/
cfg.DATA_ROOT_cluster: ../data/OpenUnReID/datasets/
cfg.LOGS_ROOT: logs
cfg.LOGS_ROOT_local: ./logs/
cfg.LOGS_ROOT_cluster: ./logs/

cfg.MODEL = edict()
cfg.MODEL.backbone: resnet50
cfg.MODEL.backbone_path_cluster: ../data/OpenUnReID/pretrained/resnet/resnet50-19c8e357.pth
cfg.MODEL.writer: /out/logs_tb/
cfg.MODEL.pooling: gem
cfg.MODEL.embed_feat: 0
cfg.MODEL.dropout: 0.0
cfg.MODEL.dsbn: True
cfg.MODEL.sync_bn: False
cfg.MODEL.samples_per_bn: 16
cfg.MODEL.mean_net: True
cfg.MODEL.alpha: 0.999
cfg.MODEL.imagenet_pretrained: True
cfg.MODEL.source_pretrained_cluster: ../data/OpenUnReID/pretrained/source_pretrain_randperson/model_best.pth
cfg.MODEL.backbone_path: ../data/OpenUnReID/pretrained/resnet/resnet50-19c8e357.pth
cfg.MODEL.source_pretrained: ../data/OpenUnReID/pretrained/source_pretrain_randperson/model_best.pth

cfg.DATA = edict()
cfg.DATA.height: 256
cfg.DATA.width: 128
cfg.DATA.norm_mean: [0.485, 0.456, 0.406]
cfg.DATA.norm_std: [0.229, 0.224, 0.225]

cfg.DATA.TRAIN = edict()
cfg.DATA.TRAIN.is_autoaug: False
cfg.DATA.TRAIN.is_flip: True
cfg.DATA.TRAIN.flip_prob: 0.5
cfg.DATA.TRAIN.is_pad: True
cfg.DATA.TRAIN.pad_size: 10
cfg.DATA.TRAIN.is_blur: False
cfg.DATA.TRAIN.blur_prob: 0.5
cfg.DATA.TRAIN.is_erase: True
cfg.DATA.TRAIN.erase_prob: 0.5
cfg.DATA.TRAIN.is_mutual_transform: True
cfg.DATA.TRAIN.mutual_times: 2

cfg.TRAIN = edict()
cfg.TRAIN.seed: 1
cfg.TRAIN.deterministic: True
cfg.TRAIN.amp: False

cfg.TRAIN.datasets = edict()
cfg.TRAIN.datasets.cuhk03-np: trainval
cfg.TRAIN.datasets.custom_randperson: train
cfg.TRAIN.unsup_dataset_indexes: [0]
cfg.TRAIN.sup_dataset_indexes: [1]
cfg.TRAIN.filtre: [True, False]
cfg.TRAIN.epochs: 10
cfg.TRAIN.iters: 120

cfg.TRAIN.LOSS = edict()

cfg.TRAIN.LOSS.losses = edict()
cfg.TRAIN.LOSS.losses.cross_entropy: 0.5
cfg.TRAIN.LOSS.losses.soft_entropy: 0.5
cfg.TRAIN.LOSS.losses.softmax_triplet: 0.2
cfg.TRAIN.LOSS.losses.soft_softmax_triplet: 0.8
cfg.TRAIN.LOSS.losses.kd_loss: 0.1
cfg.TRAIN.LOSS.losses.MMD_loss: 0.1
cfg.TRAIN.LOSS.margin: 0.0
cfg.TRAIN.val_dataset: cuhk03-np
cfg.TRAIN.val_freq: 2

cfg.TRAIN.SAMPLER = edict()
cfg.TRAIN.SAMPLER.num_instances: 4
cfg.TRAIN.SAMPLER.is_shuffle: True

cfg.TRAIN.LOADER = edict()
cfg.TRAIN.LOADER.samples_per_gpu: 16
cfg.TRAIN.LOADER.workers_per_gpu: 0

cfg.TRAIN.PSEUDO_LABELS = edict()
cfg.TRAIN.PSEUDO_LABELS.freq: 1
cfg.TRAIN.PSEUDO_LABELS.use_outliers: False
cfg.TRAIN.PSEUDO_LABELS.norm_feat: True
cfg.TRAIN.PSEUDO_LABELS.norm_center: True
cfg.TRAIN.PSEUDO_LABELS.cluster: dbscan
cfg.TRAIN.PSEUDO_LABELS.eps: [0.7]
cfg.TRAIN.PSEUDO_LABELS.min_samples: 4
cfg.TRAIN.PSEUDO_LABELS.dist_metric: jaccard
cfg.TRAIN.PSEUDO_LABELS.k1: 30
cfg.TRAIN.PSEUDO_LABELS.k2: 6
cfg.TRAIN.PSEUDO_LABELS.search_type: 0
cfg.TRAIN.PSEUDO_LABELS.cluster_num: None
cfg.TRAIN.PSEUDO_LABELS.mode: coupled_sigmoid
cfg.TRAIN.PSEUDO_LABELS.lambda_: 2
cfg.TRAIN.PSEUDO_LABELS.weighted_clustering: False

cfg.TRAIN.OPTIM = edict()
cfg.TRAIN.OPTIM.optim: adam
cfg.TRAIN.OPTIM.lr: 0.00035
cfg.TRAIN.OPTIM.weight_decay: 0.0005

cfg.TRAIN.SCHEDULER = edict()
cfg.TRAIN.SCHEDULER.lr_scheduler: None

cfg.TEST = edict()
cfg.TEST.datasets: ['msmt17', 'cuhk03-np']

cfg.TEST.LOADER = edict()
cfg.TEST.LOADER.samples_per_gpu: 32
cfg.TEST.LOADER.workers_per_gpu: 2
cfg.TEST.dist_metric: euclidean
cfg.TEST.norm_feat: True
cfg.TEST.dist_cuda: True
cfg.TEST.rerank: False
cfg.TEST.search_type: 0
cfg.TEST.k1: 20
cfg.TEST.k2: 6
cfg.TEST.lambda_value: 0.3
cfg.TEST.visrankactiv: True
cfg.launcher: pytorch
cfg.tcp_port: 23204
cfg.KD: S2P
cfg.exec: 2.0
cfg.work_dir: logs/SpCL_test_2
cfg.rank: 0
cfg.ngpus_per_node: 2
cfg.gpu: 0
cfg.total_gpus: 2
cfg.world_size: 2
appel a build_train_dataloader
The training is in a un/semi-supervised manner with 2 dataset(s) (['cuhk03-np', 'custom_randperson']),
where ['cuhk03-np'] have no labels.
0
python scripts have finished
