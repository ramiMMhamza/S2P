DATA_ROOT: '/data/ramih/Knowledge_Distilation/data/OpenUnReID/datasets/'
DATA_ROOT_cluster: './data/OpenUnReID/datasets/'

LOGS_ROOT: '/out/logs/'
LOGS_ROOT_cluster: './logs/'

MODEL:
  # architecture
  backbone: 'resnet50'
  backbone_path: "./data/OpenUnReID/pretrained/resnet/resnet50-19c8e357.pth"
  backbone_path_cluster: "./data/OpenUnReID/pretrained/resnet/resnet50-19c8e357.pth"
  pooling: 'gem'
  embed_feat: 0
  dropout: 0.

  dsbn: True

  sync_bn: False
  samples_per_bn: 16

  mean_net: True 
  alpha: 0.999 #0.3 0.7 #

  # pretraining
  imagenet_pretrained: True
  # source_pretrained_cluster: './data/OpenUnReID/pretrained/source_pretrain_duke/duke_model_best.pth'
  # source_pretrained_cluster: "./data/OpenUnReID/pretrained/source_pretrain_market/model_best.pth"
  # source_pretrained_cluster: './data/OpenUnReID/pretrained/source_pretrain_msmt_1/model_best.pth'
  source_pretrained: './data/OpenUnReID/pretrained/source_pretrain_randperson/model_best.pth'
  source_pretrained_cluster: './data/OpenUnReID/pretrained/source_pretrain_randperson/model_best.pth'

DATA:

  height: 256
  width: 128
  norm_mean: [0.485, 0.456, 0.406]
  norm_std: [0.229, 0.224, 0.225]

  TRAIN:
    # augmentation
    is_autoaug: False

    is_flip: True
    flip_prob: 0.5

    is_pad: True
    pad_size: 10

    is_blur: False
    blur_prob: 0.5

    is_erase: True
    erase_prob: 0.5

    # dual augmentation for MMT
    is_mutual_transform: False
    mutual_times: 2


TRAIN:
  seed: 1
  deterministic: True
  # mixed precision training for PyTorch>=1.6
  amp: False

  # datasets 
  datasets: {'cuhk03-np': 'trainval','custom_randperson': 'train'} #msmt17 market1501 dukemtmcreid cuhk03 cuhk03-np
  unsup_dataset_indexes: [0,]
  sup_dataset_indexes : [1,]
  filtre: [True,False]

  epochs: 1 #10
  iters: 12 #120

  LOSS:
    losses: {'hybrid_memory': 1., 'kd_loss': 0.1, 'MMD_loss': 0.1}   #for market to msmt   & RandP
    temp: 0.05
    momentum: 0.2

  # validate
  val_dataset: 'cuhk03-np'
  val_freq: 2

  # sampler
  SAMPLER:
    num_instances: 4
    is_shuffle: True

  # data loader
  LOADER:
    samples_per_gpu: 16 #32 #16
    workers_per_gpu: 2

  # pseudo labels
  PSEUDO_LABELS:
    freq: 1 # epochs
    use_outliers: True
    norm_feat: True
    norm_center: True

    cluster: 'dbscan'
    eps: [0.58, 0.6, 0.62]
    min_samples: 4 # for dbscan
    dist_metric: 'jaccard'
    k1: 30 # for jaccard distance
    k2: 6 # for jaccard distance
    search_type: 0 # 0,1,2 for GPU, 3 for CPU (work for faiss)
    cluster_num: null

    mode: 'coupled_sigmoid'  # 'only_source' 'coupled_1st_epoch_only_source' 'coupled_linear_on_source' 'coupled_linear'  
    lambda_: 2
    weighted_clustering: False
    dist_cuda: True

  # optim
  OPTIM:
    optim: 'adam'
    lr: 0.00035
    weight_decay: 0.0005

  SCHEDULER:
    lr_scheduler:  'linear' #'single_step' #"linear" #'single_step' Default:'cosine' 'linear'warmup_multi_step  single_step : for offline learning
    stepsize: 20 # for single_step & warmup_multi_step
    gamma: 0.1 # for single_step & warmup_multi_step
    max_epoch: 5 #for cosine
    n_epochs_init: 2 # for linear
    n_epochs_decay: 10 #10 # " for linear"


TEST:

  # datasets
  datasets: ["msmt17", 'cuhk03-np'] # market1501

  # data loader
  LOADER:
    samples_per_gpu: 32
    workers_per_gpu: 2

  # ranking setting
  dist_metric: 'euclidean'
  norm_feat: True
  dist_cuda: True

  # post processing
  rerank: False
  search_type: 0 # 0,1,2 for GPU, 3 for CPU (work for faiss)
  k1: 20
  k2: 6
  lambda_value: 0.3

  # visualization top k rank and activations
  visrankactiv: True
